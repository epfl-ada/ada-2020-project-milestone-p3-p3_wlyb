{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project idea and description...\n",
    "\n",
    "The original paper explores the hypothesis of chilling effects being present in people's behaviour on Wikipedia, that's to say whether people will tend to be less active in sensitive domains knowing that they are being surveilled by the government. And the conclusion was that such an effect does indeed exist.\n",
    "\n",
    "We aim in our extension to see whether those effects extend to Twitter.\n",
    "\n",
    "The logic behind our choice is that Twitter is a platform of discussion more than it is a platform of learning. So the behaviour of people should be different than on Wikipedia.\n",
    "We also know that people tend to get really vocal on Twitter, so we expect people to actually be more active in talking about those hot-topics as time progresses, especially given that the years 2013-2014 have seen a lot of terrorist-related activity throughout the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aquisition\n",
    "\n",
    "At first we need to obtain tweets containing the same keywords chosen in the original paper, to do so we use the Python module `Twint` (not to be confused with the Swiss payment method) to retrieve those tweets for our selected dates.\n",
    "We only focus on Tweets in English to match the scope of the original paper.\n",
    "\n",
    "We need to get all the following keywords from twitter :\n",
    "\n",
    "* abu sayyaf\n",
    "* afghanistan\n",
    "* agro\n",
    "* al-qaeda\n",
    "* al-qaeda in the arabian peninsula\n",
    "* al-qaeda in the islamic maghreb\n",
    "* al-shabaab\n",
    "* ammonium nitrate\n",
    "* attack\n",
    "* biological weapon\n",
    "* car bomb\n",
    "* chemical weapon\n",
    "* conventional weapon\n",
    "* dirty bomb\n",
    "* eco-terrorism\n",
    "* environmental terrorism\n",
    "* euskadi ta askatasuna\n",
    "* extremism\n",
    "* farc\n",
    "* fundamentalism,\n",
    "* hamas\n",
    "* hezbollah\n",
    "* improvised explosive device\n",
    "* iran\n",
    "* iraq\n",
    "* irish republican army\n",
    "* islamist\n",
    "* jihad\n",
    "* nationalism\n",
    "* nigeria\n",
    "* nuclear\n",
    "* nuclear enrichment\n",
    "* pakistan\n",
    "* palestine liberation front\n",
    "* pirates\n",
    "* plo\n",
    "* political radicalism\n",
    "* recruitment\n",
    "* somalia\n",
    "* suicide attack\n",
    "* suicide bomber\n",
    "* taliban\n",
    "* tamil tigers\n",
    "* tehrik-i-taliban pakistan\n",
    "* terror\n",
    "* terrorism\n",
    "* weapons-grade\n",
    "* yemen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping script\n",
    "\n",
    "Bellow we demonstrate the script that we used to retreive the data using the `twint` module. As the scripts were run in a command line fashion we used the `argparse` module to give command line style arguments to the script like start/end dates and keywords. This script could then be executed on multiple machines to get the full 47 keyword datasets.\n",
    "\n",
    "Example of the command : `python3 scraper.py -q \"abu sayyaf\"` or with an end date `python3 scraper.py -q \"abu sayyaf\" -e 2012-05-06`\n",
    "\n",
    "```python\n",
    "import twint\n",
    "import argparse\n",
    "\n",
    "# get arguments from command line\n",
    "# only the keyword is required, the other have default values \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-q', '--query', type=str, required=True)\n",
    "parser.add_argument('-s', '--start', type=str, default='2012-01-01')\n",
    "parser.add_argument('-e', '--end', type=str, default='2014-09-01')\n",
    "args = parser.parse_args()\n",
    "\n",
    "config = twint.Config()\n",
    "config.Limit = 5\n",
    "config.Hide_output = False\n",
    "config.Lang = \"en\"\n",
    "config.Since = args.start\n",
    "config.Until = args.end\n",
    "config.Store_csv = True\n",
    "config.Search = args.query\n",
    "config.Output = \"_\".join([args.query, args.start, args.end]) + \".csv\"\n",
    "# make search\n",
    "print(f'Running search for \"{args.query}\" between {args.start} and {args.end}.')\n",
    "twint.run.Search(config)\n",
    "```\n",
    "\n",
    "We had to restart the scripts often as sometimes the network went down or it was hitting an error. The convinience was that the scraped results are automatically saved to the specified output file so that you don't lose 2 days of computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring the scraping process\n",
    "\n",
    "Scraping took a lot of time and the dataset we collected became quickly huge. Here are some insights and explanations.\n",
    "\n",
    "The columns we decided to keep during the pre-processing step :\n",
    "```python\n",
    "keep_columns = ['id', 'conversation_id', 'created_at', 'date', 'time', 'user_id', 'username', \n",
    "                'name', 'tweet', 'language', 'mentions', 'urls', 'photos', 'replies_count', \n",
    "                'retweets_count', 'likes_count', 'hashtags', 'link', 'retweet', 'video', \n",
    "                'thumbnail', 'reply_to']\n",
    "```\n",
    "\n",
    "We also defined the column types to try and speed the loading :\n",
    "```python\n",
    "defined_types = {'id': 'int64', 'conversation_id': 'int64', 'date': 'str', 'time': 'str',\n",
    "                 'user_id': 'int64', 'username': 'str', 'name': 'str', 'tweet': 'str', \n",
    "                 'language': 'category', 'mentions': 'str', 'urls': 'str', 'photos': 'str',\n",
    "                 'replies_count': 'int64', 'retweets_count': 'int64', 'likes_count': 'int64',\n",
    "                 'hashtags': 'str', 'link': 'str', 'retweet': 'bool', 'video': 'bool', \n",
    "                 'thumbnail': 'str', 'reply_to': 'str'}\n",
    "```\n",
    "\n",
    "The scraping was done locally and we gathered some informations to better understand the data we were dealling with :\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>keyword</th>\n",
    "      <th>mem (RAM in bytes)</th>\n",
    "      <th>length (tweets)</th>\n",
    "      <th>load_time (seconds)</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>abu sayyaf</td>\n",
    "      <td>4865767</td>\n",
    "      <td>31381</td>\n",
    "      <td>0.235500</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>afghanistan</td>\n",
    "      <td>968202453</td>\n",
    "      <td>6246447</td>\n",
    "      <td>45.314392</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>agro</td>\n",
    "      <td>173245992</td>\n",
    "      <td>1117696</td>\n",
    "      <td>9.340182</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>al-qaeda</td>\n",
    "      <td>122046622</td>\n",
    "      <td>787386</td>\n",
    "      <td>5.864598</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>al-qaeda in the arabian peninsula</td>\n",
    "      <td>242026</td>\n",
    "      <td>1558</td>\n",
    "      <td>0.260090</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>al-qaeda in the islamic maghreb</td>\n",
    "      <td>173973</td>\n",
    "      <td>1119</td>\n",
    "      <td>0.023007</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>al-shabaab</td>\n",
    "      <td>18349519</td>\n",
    "      <td>118373</td>\n",
    "      <td>0.970689</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>ammonium nitrate</td>\n",
    "      <td>2227611</td>\n",
    "      <td>14361</td>\n",
    "      <td>0.142450</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>biological weapon</td>\n",
    "      <td>1440179</td>\n",
    "      <td>9281</td>\n",
    "      <td>0.071740</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>car bomb</td>\n",
    "      <td>74192061</td>\n",
    "      <td>478647</td>\n",
    "      <td>3.209042</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>10</th>\n",
    "      <td>chemical weapon</td>\n",
    "      <td>10538457</td>\n",
    "      <td>67979</td>\n",
    "      <td>0.562371</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>11</th>\n",
    "      <td>conventional weapon</td>\n",
    "      <td>288886</td>\n",
    "      <td>1858</td>\n",
    "      <td>0.036680</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>12</th>\n",
    "      <td>dirty bomb</td>\n",
    "      <td>9855551</td>\n",
    "      <td>63573</td>\n",
    "      <td>0.422941</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>13</th>\n",
    "      <td>eco-terrorism</td>\n",
    "      <td>628197</td>\n",
    "      <td>4047</td>\n",
    "      <td>0.042559</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>14</th>\n",
    "      <td>environmental terrorism</td>\n",
    "      <td>137222</td>\n",
    "      <td>882</td>\n",
    "      <td>0.015497</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>15</th>\n",
    "      <td>euskadi ta askatasuna</td>\n",
    "      <td>228079</td>\n",
    "      <td>1461</td>\n",
    "      <td>0.014286</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>16</th>\n",
    "      <td>extremism</td>\n",
    "      <td>55538658</td>\n",
    "      <td>358294</td>\n",
    "      <td>2.734478</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>17</th>\n",
    "      <td>farc</td>\n",
    "      <td>553848730</td>\n",
    "      <td>3573206</td>\n",
    "      <td>26.877547</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>18</th>\n",
    "      <td>fundamentalism</td>\n",
    "      <td>22248274</td>\n",
    "      <td>143526</td>\n",
    "      <td>1.583067</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>19</th>\n",
    "      <td>hamas</td>\n",
    "      <td>648181655</td>\n",
    "      <td>4181797</td>\n",
    "      <td>32.523051</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>20</th>\n",
    "      <td>hezbollah</td>\n",
    "      <td>40189679</td>\n",
    "      <td>259277</td>\n",
    "      <td>3.038919</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>21</th>\n",
    "      <td>improvised explosive device</td>\n",
    "      <td>1452690</td>\n",
    "      <td>9366</td>\n",
    "      <td>0.159687</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>22</th>\n",
    "      <td>iran</td>\n",
    "      <td>3270850074</td>\n",
    "      <td>21102238</td>\n",
    "      <td>273.121536</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>23</th>\n",
    "      <td>iraq</td>\n",
    "      <td>1530368273</td>\n",
    "      <td>9873323</td>\n",
    "      <td>140.079643</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>24</th>\n",
    "      <td>irish republican army</td>\n",
    "      <td>783019</td>\n",
    "      <td>5041</td>\n",
    "      <td>2.799364</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>25</th>\n",
    "      <td>islamist</td>\n",
    "      <td>155708870</td>\n",
    "      <td>1004562</td>\n",
    "      <td>7.137926</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>26</th>\n",
    "      <td>jihad</td>\n",
    "      <td>342291226</td>\n",
    "      <td>2208310</td>\n",
    "      <td>15.917475</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>27</th>\n",
    "      <td>nationalism</td>\n",
    "      <td>47336082</td>\n",
    "      <td>305374</td>\n",
    "      <td>2.629160</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>28</th>\n",
    "      <td>nigeria</td>\n",
    "      <td>3101185190</td>\n",
    "      <td>20007626</td>\n",
    "      <td>220.365958</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>30</th>\n",
    "      <td>nuclear</td>\n",
    "      <td>1528390409</td>\n",
    "      <td>9860563</td>\n",
    "      <td>72.915037</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>29</th>\n",
    "      <td>nuclear enrichment</td>\n",
    "      <td>3812867</td>\n",
    "      <td>24593</td>\n",
    "      <td>8.927966</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>31</th>\n",
    "      <td>palestine liberation front</td>\n",
    "      <td>17231</td>\n",
    "      <td>109</td>\n",
    "      <td>2.133325</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>32</th>\n",
    "      <td>pirates</td>\n",
    "      <td>2616191136</td>\n",
    "      <td>16878632</td>\n",
    "      <td>160.441553</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>33</th>\n",
    "      <td>plo</td>\n",
    "      <td>201551066</td>\n",
    "      <td>1300318</td>\n",
    "      <td>15.027318</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>34</th>\n",
    "      <td>political radicalism</td>\n",
    "      <td>60933</td>\n",
    "      <td>391</td>\n",
    "      <td>0.422480</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>35</th>\n",
    "      <td>recruitment</td>\n",
    "      <td>970214011</td>\n",
    "      <td>6259425</td>\n",
    "      <td>44.130364</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>36</th>\n",
    "      <td>somalia</td>\n",
    "      <td>321910033</td>\n",
    "      <td>2076819</td>\n",
    "      <td>15.855634</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>37</th>\n",
    "      <td>suicide attack</td>\n",
    "      <td>24404292</td>\n",
    "      <td>157436</td>\n",
    "      <td>1.422346</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>38</th>\n",
    "      <td>suicide bomber</td>\n",
    "      <td>76492889</td>\n",
    "      <td>493491</td>\n",
    "      <td>3.353994</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>39</th>\n",
    "      <td>taliban</td>\n",
    "      <td>598092678</td>\n",
    "      <td>3858642</td>\n",
    "      <td>26.805472</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>40</th>\n",
    "      <td>tamil tigers</td>\n",
    "      <td>1250932</td>\n",
    "      <td>8060</td>\n",
    "      <td>0.681614</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>41</th>\n",
    "      <td>tehrik-i-taliban pakistan</td>\n",
    "      <td>218540</td>\n",
    "      <td>1404</td>\n",
    "      <td>0.054258</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>42</th>\n",
    "      <td>terror</td>\n",
    "      <td>2362431328</td>\n",
    "      <td>15241472</td>\n",
    "      <td>127.771983</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>43</th>\n",
    "      <td>terrorism</td>\n",
    "      <td>481497811</td>\n",
    "      <td>3106417</td>\n",
    "      <td>27.226853</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>44</th>\n",
    "      <td>weapons-grade</td>\n",
    "      <td>4045884</td>\n",
    "      <td>26092</td>\n",
    "      <td>0.893699</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>45</th>\n",
    "      <td>yemen</td>\n",
    "      <td>519440710</td>\n",
    "      <td>3351210</td>\n",
    "      <td>25.210480</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Loading all files simutaneously would take 20.86GB of memory.\n",
    "\n",
    "We got 134 million tweets over the 32 months of the periode accross the 46 keywords.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the distribution of our data\n",
    "\n",
    "The most active topics in our keyword list are :\n",
    "- iran\n",
    "- nigeria\n",
    "- pirates\n",
    "- terror\n",
    "\n",
    "All four with more than 10 million tweets.\n",
    "\n",
    "The least active keywords are :\n",
    "- environmental terrorism\n",
    "- political radicalism\n",
    "- palestine liberation front\n",
    "\n",
    "They have less than 1000 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "stats_df = pd.read_csv('stats_df.csv')\n",
    "plt.hist(stats_df.length, bins=50)\n",
    "# plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Number of keywords')\n",
    "plt.xlabel('Number of tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that a lot of the keywords have not too much tweets and just a few kewords have a big number of tweets, it's powerlaw time again !\n",
    "\n",
    "We would like to adress some caveats, as can be seen in the table and in the datastory, we did not manage to aggregate the data for the keyword `attack`and `pakistan` in time to showcase in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Wrangling\n",
    "\n",
    "The data as retrieved is quite messy (as Tweets tend to be) and it's not all in English, so we first filter the dataframes by language since some non-English Tweets do slip by Twint's filter.\n",
    "\n",
    "We tried using an aggressive approach to filter all entries containing non-standard characters using regex, this heavy approach seemed to be subpar leaving non-English tweets and removing some English ones.\n",
    "\n",
    "We opted to just filtering by the column `language` and saving cleaned CSVs for the next step, this has been replaced by a single line in the aggregation step. So this code is here just for decoration and isn't really used anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```python\n",
    "from os import scandir\n",
    "\n",
    "data_path = './data/'\n",
    "cleaned_data_path = data_path + 'cleaned/'\n",
    "for element in scandir(data_path):\n",
    "    if element.name.endswith('.gz'):\n",
    "        df = pd.read_csv(data_path+element.name, lineterminator='\\n', encoding='UTF-8', compression='gzip')\n",
    "        df['tweet'] = df.tweet.str.replace(r'http\\S+', 'URL').str.replace(r'@\\S+', 'TWITTER_HANDLE').str.replace(r'#\\S+', 'HASHTAG')\n",
    "        df = df[df.language == 'en']\n",
    "        # Alternatively, drop all rows having non-standard characters\n",
    "        #df.drop(df[df.tweet.str.contains(fr'[^a-zA-Z!@#►&^$%~“”»`\\[\\]…:/‘’?–+=―•.;,_—\\'\\\"\\-\\(\\)\\d\\s{get_emoji_regexp().pattern}]')].index, inplace=True)\n",
    "        df.to_csv(cleaned_data_path+element.name, compression='gzip')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have the issue of having non-relevant Tweets slipping into our dataset, those have been among the highlights of this project, here's a sample:\n",
    "\n",
    "For the keyword `dirty bomb` we found the following tweets in the data:\n",
    "\n",
    "* I got really cheap bath bombs &amp; instead of turning my water a pretty color it just made my bath look dirty😑😖\n",
    "* \"I'm not a dirty whore, I bathe and I don't get paid. I'm a nice lady who gives bomb ass blowjobs \" well folks, there you have it ; )\n",
    "\n",
    "and for the keyword `Jihad`\n",
    "* Wheres the loves for JIHAD AMARI JONES??\n",
    "\n",
    "At first we tried to filter each dataframe by dropping all tweets containing \"positive\" words chosen per dataframe (e.g. the word `love` for `jihad`), but that ended up eliminating a good portion of Tweets that were actually relevant to our topic such as the following:\n",
    "\n",
    "* \"What does #Jihad really mean?\" To struggle for love and to condemn hate #MyJihad featured in #Urdunewspaper #India.\n",
    "\n",
    "And so we chose to keep those irrelevant Tweets that we deem to be a minority in the dataset and proceed to the modelling step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis of the tweets\n",
    "\n",
    "### Interrupted time series with regression\n",
    "We will now focus on getting an understanding of the tweet distribution over time, and how the massive revelations of online surveillance in June 2013 might have caused a chilling effect. We will follow the paper's original way of doing the interrupted time series, with regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see what those big files yield by reading one. We need to first find all the archives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 archives\n"
     ]
    }
   ],
   "source": [
    "archive_pathnames = glob.glob('./data/*.gz')\n",
    "print(f\"Found {len(archive_pathnames)} archives\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what is in the first archive ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9299, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>photos</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>video</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>reply_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>506278868614148097</td>\n",
       "      <td>506278868614148097</td>\n",
       "      <td>2014-09-01 05:14:23 CEST</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>05:14:23</td>\n",
       "      <td>8.343178e+07</td>\n",
       "      <td>starman1981</td>\n",
       "      <td>truckerstrong news</td>\n",
       "      <td>ISIS laptop reveals terror group were working ...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/starman1981/status/5062788...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>506272708037214208</td>\n",
       "      <td>506272708037214208</td>\n",
       "      <td>2014-09-01 04:49:54 CEST</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>04:49:54</td>\n",
       "      <td>7.134575e+08</td>\n",
       "      <td>patriotsorg</td>\n",
       "      <td>Patriots Billboard</td>\n",
       "      <td>#SEIZED ISIS LAPTOP REVEALS THEY’RE DEVELOPING...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['seized']</td>\n",
       "      <td>https://twitter.com/PatriotsOrg/status/5062727...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>506263382459428864</td>\n",
       "      <td>506263382459428864</td>\n",
       "      <td>2014-09-01 04:12:50 CEST</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>04:12:50</td>\n",
       "      <td>2.630728e+08</td>\n",
       "      <td>mlgeek</td>\n",
       "      <td>My Little Geek</td>\n",
       "      <td>@bjorntipling Perhaps Swift is a biological we...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/mlgeek/status/506263382459...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>506261754197061632</td>\n",
       "      <td>506261754197061632</td>\n",
       "      <td>2014-09-01 04:06:22 CEST</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>04:06:22</td>\n",
       "      <td>2.510451e+09</td>\n",
       "      <td>msgubot</td>\n",
       "      <td>Cédric Moro (backup)</td>\n",
       "      <td>G+ #ebola USA created Ebola virus as biologica...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['ebola']</td>\n",
       "      <td>https://twitter.com/MSGUBOT/status/50626175419...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>506239829819281408</td>\n",
       "      <td>506239829819281408</td>\n",
       "      <td>2014-09-01 02:39:15 CEST</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>02:39:15</td>\n",
       "      <td>7.134575e+08</td>\n",
       "      <td>patriotsorg</td>\n",
       "      <td>Patriots Billboard</td>\n",
       "      <td>#SEIZED ISIS LAPTOP REVEALS THEY’RE DEVELOPING...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['seized']</td>\n",
       "      <td>https://twitter.com/PatriotsOrg/status/5062398...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id     conversation_id                created_at  \\\n",
       "0  506278868614148097  506278868614148097  2014-09-01 05:14:23 CEST   \n",
       "1  506272708037214208  506272708037214208  2014-09-01 04:49:54 CEST   \n",
       "2  506263382459428864  506263382459428864  2014-09-01 04:12:50 CEST   \n",
       "3  506261754197061632  506261754197061632  2014-09-01 04:06:22 CEST   \n",
       "4  506239829819281408  506239829819281408  2014-09-01 02:39:15 CEST   \n",
       "\n",
       "         date      time       user_id     username                  name  \\\n",
       "0  2014-09-01  05:14:23  8.343178e+07  starman1981    truckerstrong news   \n",
       "1  2014-09-01  04:49:54  7.134575e+08  patriotsorg    Patriots Billboard   \n",
       "2  2014-09-01  04:12:50  2.630728e+08       mlgeek        My Little Geek   \n",
       "3  2014-09-01  04:06:22  2.510451e+09      msgubot  Cédric Moro (backup)   \n",
       "4  2014-09-01  02:39:15  7.134575e+08  patriotsorg    Patriots Billboard   \n",
       "\n",
       "                                               tweet language  ... photos  \\\n",
       "0  ISIS laptop reveals terror group were working ...       en  ...     []   \n",
       "1  #SEIZED ISIS LAPTOP REVEALS THEY’RE DEVELOPING...       en  ...     []   \n",
       "2  @bjorntipling Perhaps Swift is a biological we...       en  ...     []   \n",
       "3  G+ #ebola USA created Ebola virus as biologica...       en  ...     []   \n",
       "4  #SEIZED ISIS LAPTOP REVEALS THEY’RE DEVELOPING...       en  ...     []   \n",
       "\n",
       "  replies_count retweets_count likes_count    hashtags  \\\n",
       "0             0            0.0         0.0          []   \n",
       "1             0            3.0         1.0  ['seized']   \n",
       "2             0            0.0         0.0          []   \n",
       "3             0            0.0         0.0   ['ebola']   \n",
       "4             1            2.0         1.0  ['seized']   \n",
       "\n",
       "                                                link retweet  video thumbnail  \\\n",
       "0  https://twitter.com/starman1981/status/5062788...   False  False       NaN   \n",
       "1  https://twitter.com/PatriotsOrg/status/5062727...   False  False       NaN   \n",
       "2  https://twitter.com/mlgeek/status/506263382459...   False  False       NaN   \n",
       "3  https://twitter.com/MSGUBOT/status/50626175419...   False  False       NaN   \n",
       "4  https://twitter.com/PatriotsOrg/status/5062398...   False  False       NaN   \n",
       "\n",
       "  reply_to  \n",
       "0       []  \n",
       "1       []  \n",
       "2       []  \n",
       "3       []  \n",
       "4       []  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(archive_pathnames[0])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a lot of information there. But what we are interested in is the user interactions around a topic that they might the government to track, for example. Therefore, we can count the number of tweets themselves, not any of their content or information, but also the number of likes and rerplies ! Each of these actions can make the user fear such surveillance. Retweets also, but because we also collect the retweets themselves, they are already there ! Therefore, we will first count the number of tweets per month, with the number of likes and retweets added as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replies_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>user_interactions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-31</th>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>207</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-29</th>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>177</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-31</th>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>192</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-30</th>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>156</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-31</th>\n",
       "      <td>46</td>\n",
       "      <td>17</td>\n",
       "      <td>237</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            replies_count  likes_count  tweet_count  user_interactions\n",
       "date                                                                  \n",
       "2012-01-31             49           51          207                307\n",
       "2012-02-29             33           27          177                237\n",
       "2012-03-31             37           10          192                239\n",
       "2012-04-30             40           32          156                228\n",
       "2012-05-31             46           17          237                300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only interesting columns and sum them all together by month. We set to parse dates so we can group by month\n",
    "df = pd.read_csv(archive_pathnames[0], usecols=[\"date\", \"likes_count\", \"replies_count\"], parse_dates=[\"date\"], lineterminator='\\n')\n",
    "df[\"tweet_count\"] = 1\n",
    "grouped_df = df.set_index('date').groupby(pd.Grouper(freq='M')).sum()\n",
    "grouped_df[\"user_interactions\"] = grouped_df[\"likes_count\"] +  grouped_df[\"tweet_count\"] +  grouped_df[\"replies_count\"]\n",
    "\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to merge all twitter keyworkds into the same dataframe, therefore we will give the name of the keywork to the column where all values are summed, instead of just user_interactions. Let's extract the name from the archive path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/biological weapon_full.gz\n"
     ]
    }
   ],
   "source": [
    "print(archive_pathnames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'biological weapon'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Knowing what the file path looks like, we can extract the name\n",
    "name = re.search(r\"(?<=data/).*?(?=_full)\", archive_pathnames[0]).group(0)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replies_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>biological weapon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-31</th>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>207</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-29</th>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>177</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-31</th>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>192</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-30</th>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>156</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-31</th>\n",
       "      <td>46</td>\n",
       "      <td>17</td>\n",
       "      <td>237</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            replies_count  likes_count  tweet_count  biological weapon\n",
       "date                                                                  \n",
       "2012-01-31             49           51          207                307\n",
       "2012-02-29             33           27          177                237\n",
       "2012-03-31             37           10          192                239\n",
       "2012-04-30             40           32          156                228\n",
       "2012-05-31             46           17          237                300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just set this name to the column and go to the next zip !\n",
    "grouped_df.rename(columns={\"user_interactions\": name}, inplace=True)\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now implement a for loop to aggregate all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/biological weapon_full.gz file\n",
      "Shape is : (9281, 3) \n",
      "\n",
      "Reading ./data/nuclear_full.gz file\n",
      "Shape is : (9860563, 3) \n",
      "\n",
      "Reading ./data/improvised explosive device_full.gz file\n",
      "Shape is : (9366, 3) \n",
      "\n",
      "Reading ./data/iran_full.gz file\n",
      "Shape is : (21102238, 3) \n",
      "\n",
      "Reading ./data/nuclear enrichment_full.gz file\n",
      "Shape is : (24593, 3) \n",
      "\n",
      "Reading ./data/hamas_full.gz file\n",
      "Shape is : (4181797, 3) \n",
      "\n",
      "Reading ./data/extremism_full.gz file\n",
      "Shape is : (358294, 3) \n",
      "\n",
      "Reading ./data/environmental terrorism_full.gz file\n",
      "Shape is : (882, 3) \n",
      "\n",
      "Reading ./data/al-qaeda in the islamic maghreb_full.gz file\n",
      "Shape is : (1119, 3) \n",
      "\n",
      "Reading ./data/taliban_full.gz file\n",
      "Shape is : (3858642, 3) \n",
      "\n",
      "Reading ./data/abu sayyaf_full.gz file\n",
      "Shape is : (31381, 3) \n",
      "\n",
      "Reading ./data/yemen_full.gz file\n",
      "Shape is : (3351210, 3) \n",
      "\n",
      "Reading ./data/agro_full.gz file\n",
      "Shape is : (1117696, 3) \n",
      "\n",
      "Reading ./data/islamist_full.gz file\n",
      "Shape is : (1004562, 3) \n",
      "\n",
      "Reading ./data/al-qaeda_full.gz file\n",
      "Shape is : (787386, 3) \n",
      "\n",
      "Reading ./data/ammonium nitrate_full.gz file\n",
      "Shape is : (14361, 3) \n",
      "\n",
      "Reading ./data/recruitment_full.gz file\n",
      "Shape is : (6259425, 3) \n",
      "\n",
      "Reading ./data/plo_full.gz file\n",
      "Shape is : (1300318, 3) \n",
      "\n",
      "Reading ./data/nigeria_full.gz file\n",
      "Shape is : (20007626, 3) \n",
      "\n",
      "Reading ./data/suicide bomber_full.gz file\n",
      "Shape is : (493491, 3) \n",
      "\n",
      "Reading ./data/nationalism_full.gz file\n",
      "Shape is : (305374, 3) \n",
      "\n",
      "Reading ./data/jihad_full.gz file\n",
      "Shape is : (2208310, 3) \n",
      "\n",
      "Reading ./data/farc_full.gz file\n",
      "Shape is : (3573206, 3) \n",
      "\n",
      "Reading ./data/al-qaeda in the arabian peninsula_full.gz file\n",
      "Shape is : (1558, 3) \n",
      "\n",
      "Reading ./data/somalia_full.gz file\n",
      "Shape is : (2076819, 3) \n",
      "\n",
      "Reading ./data/euskadi ta askatasuna_full.gz file\n",
      "Shape is : (1461, 3) \n",
      "\n",
      "Reading ./data/hezbollah_full.gz file\n",
      "Shape is : (259277, 3) \n",
      "\n",
      "Reading ./data/palestine liberation front_full.gz file\n",
      "Shape is : (109, 3) \n",
      "\n",
      "Reading ./data/political radicalism_full.gz file\n",
      "Shape is : (391, 3) \n",
      "\n",
      "Reading ./data/conventional weapon_full.gz file\n",
      "Shape is : (1858, 3) \n",
      "\n",
      "Reading ./data/pirates_full.gz file\n",
      "Shape is : (16878632, 3) \n",
      "\n",
      "Reading ./data/irish republican army_full.gz file\n",
      "Shape is : (5041, 3) \n",
      "\n",
      "Reading ./data/afghanistan_full.gz file\n",
      "Shape is : (6246447, 3) \n",
      "\n",
      "Reading ./data/terrorism_full.gz file\n",
      "Shape is : (3106417, 3) \n",
      "\n",
      "Reading ./data/tamil tigers_full.gz file\n",
      "Shape is : (8060, 3) \n",
      "\n",
      "Reading ./data/iraq_full.gz file\n"
     ]
    }
   ],
   "source": [
    "# print(pd.read_csv(archive_pathnames[0], usecols=[\"date\", \"likes_count\"]))\n",
    "monthly_counts = pd.DataFrame([])\n",
    "\n",
    "for archive_pathname in archive_pathnames:\n",
    "    print(f\"Reading {archive_pathname} file\")\n",
    "    df = pd.read_csv(archive_pathname, usecols=[\"date\", \"likes_count\", \"replies_count\"], parse_dates=[\"date\"], lineterminator='\\n')\n",
    "    print(f\"Shape is : {df.shape} \\n\")\n",
    "\n",
    "    df[\"tweet_count\"] = 1\n",
    "    df = df.set_index('date').groupby(pd.Grouper(freq='M')).sum()\n",
    "    df[\"user_interactions\"] = df[\"likes_count\"] +  df[\"tweet_count\"] +  df[\"replies_count\"]\n",
    "    name = re.search(r\"(?<=data/).*?(?=_full)\", archive_pathname).group(0)\n",
    "\n",
    "    df.rename(columns={\"user_interactions\": name}, inplace=True)\n",
    "    \n",
    "    monthly_counts = pd.concat([monthly_counts, df[name]], axis=1)\n",
    "monthly_counts.index = pd.to_datetime(monthly_counts.index) # Make sure it is datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {np.round(monthly_counts.sum().sum()/1000000, 2)} million actions !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary to get working faster !\n",
    "# monthly_counts.to_csv(\"./monthly_actions.csv\")\n",
    "# monthly_counts = pd.read_csv(\"./monthly_actions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now have a quick glance at all the values we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# define figure\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# big frame for main labels\n",
    "fig.add_subplot(111, frameon=False)\n",
    "plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False, pad=60)\n",
    "plt.grid(False)\n",
    "plt.xlabel(\"Months\", fontsize=22)\n",
    "plt.ylabel(\"Views\", fontsize=22)\n",
    "\n",
    "# define number of columns and rows of plot\n",
    "col = 4\n",
    "row = len(monthly_counts.columns)//col\n",
    "\n",
    "# plot all topics\n",
    "ax = fig.subplots(row, col, sharey=False, sharex=True)\n",
    "\n",
    "for i, article_name in enumerate(monthly_counts):\n",
    "    axis = ax[i//col, i%col]\n",
    "    sns.lineplot(data=monthly_counts[f\"{article_name}\"], ax=axis)\n",
    "    axis.set_title(article_name)\n",
    "    plt.setp(axis.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "    axis.set_ylabel(\"\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this graph we can look for missing values, or things that look anormal. TODO : discuss the weird things once we have complete data\n",
    "\n",
    "In the original article, they study the period of 32 months from january 2012 to end of august 2014. We will therefore restrict our period to the be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studied_article_actions = monthly_counts[\"2012-01-01\":\"2014-08-31\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we will create the interrupted time series plot, without regression first :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_actions = pd.DataFrame(studied_article_actions.sum(axis=1), columns=[\"actions\"])\n",
    "all_actions[\"month_nb\"] = range(1, 33)\n",
    "\n",
    "after_revelations_month = 17 # 16 first months including June 2013, but index starts at 0 so we add 1 \n",
    "\n",
    "# define figure\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "# big frame for main labels\n",
    "plt.title(\"Monthly actions on all topics\")\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Total Actions\")\n",
    "plt.xticks(np.arange(0, 33, 2.0))\n",
    "plt.scatter(x=all_actions[\"month_nb\"], y=all_actions.actions)\n",
    "plt.axvline(after_revelations_month+0.5, color='orange', label='Mid June 2013') # Plot a vertical line mid June \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do the regression, to compare the trend before and after the studied interruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Do linear regression with ols\n",
    "mod_before = smf.ols(formula='actions ~ month_nb',\n",
    "              data=all_actions[:after_revelations_month])\n",
    "res_before = mod_before.fit()\n",
    "\n",
    "mod_after = smf.ols(formula='actions ~ month_nb',\n",
    "              data=all_actions[after_revelations_month:])\n",
    "res_after = mod_after.fit()\n",
    "\n",
    "before_intercept = res_before.params[0]\n",
    "before_slope = res_before.params[1]\n",
    "\n",
    "after_intercept = res_after.params[0]\n",
    "after_slope = res_after.params[1]\n",
    "\n",
    "print(f\"Before period has intercept={before_intercept} and slope={before_slope}\")\n",
    "\n",
    "print(f\"After period has intercept={after_intercept} and slope={after_slope}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we will plot both regressions, on each side of the interruption :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define figure\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "# big frame for main labels\n",
    "plt.title(\"Interrupted regression of twitter actions across keywords\")\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Total actions\")\n",
    "plt.xticks(np.arange(0, 33, 2.0))\n",
    "plt.scatter(x=range(1, 33), y=all_actions.actions)\n",
    "plt.axvline(after_revelations_month+0.5, color='orange', label='Mid June 2013') # Plot a vertical line mid June \n",
    "\n",
    "# Now we'll add the before period regression line\n",
    "plt.plot(all_actions[:after_revelations_month].month_nb, all_actions[:after_revelations_month].month_nb*before_slope+before_intercept, label=\"Trend Pre-June 2013\")\n",
    "\n",
    "# And the after period\n",
    "plt.plot(all_actions[after_revelations_month:].month_nb, all_actions[after_revelations_month:].month_nb*after_slope+after_intercept, label=\"Trend Post-June 2013\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
