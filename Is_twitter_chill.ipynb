{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project idea and description...\n",
    "\n",
    "\n",
    "Tadatadatada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aquisition\n",
    "\n",
    "In the first ... \n",
    "\n",
    "We need to get all the following keywords from twitter :\n",
    "\n",
    "abu sayyaf,\n",
    "afghanistan,\n",
    "agro,\n",
    "al-qaeda,\n",
    "al-qaeda in the arabian peninsula,\n",
    "al-qaeda in the islamic maghreb,\n",
    "al-shabaab,\n",
    "ammonium nitrate,\n",
    "attack,\n",
    "biological weapon,\n",
    "car bomb,\n",
    "chemical weapon,\n",
    "conventional weapon,\n",
    "dirty bomb,\n",
    "eco-terrorism,\n",
    "environmental terrorism,\n",
    "euskadi ta askatasuna,\n",
    "extremism,\n",
    "farc,\n",
    "fundamentalism,\n",
    "hamas,\n",
    "hezbollah,\n",
    "improvised explosive device,\n",
    "iran,\n",
    "iraq,\n",
    "irish republican army,\n",
    "islamist,\n",
    "jihad,\n",
    "nationalism,\n",
    "nigeria,\n",
    "nuclear,\n",
    "nuclear enrichment,\n",
    "pakistan,\n",
    "palestine liberation front,\n",
    "pirates,\n",
    "plo,\n",
    "political radicalism,\n",
    "recruitment,\n",
    "somalia,\n",
    "suicide attack,\n",
    "suicide bomber,\n",
    "taliban,\n",
    "tamil tigers,\n",
    "tehrik-i-taliban pakistan,\n",
    "terror,\n",
    "terrorism,\n",
    "weapons-grade,\n",
    "yemen,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the tweets\n",
    "\n",
    "### Interrupted time series with regression\n",
    "We will now focus on getting an understanding of the tweet distribution over time, and how the massive revelations of online surveillance in June 2013 might have caused a chilling effect. We will follow the paper's original way of doing the interrupted time series, with regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see what those big files yield by reading one. We need to first find all the archives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 archives\n"
     ]
    }
   ],
   "source": [
    "archive_pathnames = glob.glob('./data/*.gz')\n",
    "print(f\"Found {len(archive_pathnames)} archives\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what is in the first archive ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9299, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>photos</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>video</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>reply_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>506278868614148097</td>\n",
       "      <td>506278868614148097</td>\n",
       "      <td>2014-09-01 05:14:23 CEST</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>05:14:23</td>\n",
       "      <td>8.343178e+07</td>\n",
       "      <td>starman1981</td>\n",
       "      <td>truckerstrong news</td>\n",
       "      <td>ISIS laptop reveals terror group were working ...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/starman1981/status/5062788...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>506272708037214208</td>\n",
       "      <td>506272708037214208</td>\n",
       "      <td>2014-09-01 04:49:54 CEST</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>04:49:54</td>\n",
       "      <td>7.134575e+08</td>\n",
       "      <td>patriotsorg</td>\n",
       "      <td>Patriots Billboard</td>\n",
       "      <td>#SEIZED ISIS LAPTOP REVEALS THEY’RE DEVELOPING...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['seized']</td>\n",
       "      <td>https://twitter.com/PatriotsOrg/status/5062727...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>506263382459428864</td>\n",
       "      <td>506263382459428864</td>\n",
       "      <td>2014-09-01 04:12:50 CEST</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>04:12:50</td>\n",
       "      <td>2.630728e+08</td>\n",
       "      <td>mlgeek</td>\n",
       "      <td>My Little Geek</td>\n",
       "      <td>@bjorntipling Perhaps Swift is a biological we...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/mlgeek/status/506263382459...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>506261754197061632</td>\n",
       "      <td>506261754197061632</td>\n",
       "      <td>2014-09-01 04:06:22 CEST</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>04:06:22</td>\n",
       "      <td>2.510451e+09</td>\n",
       "      <td>msgubot</td>\n",
       "      <td>Cédric Moro (backup)</td>\n",
       "      <td>G+ #ebola USA created Ebola virus as biologica...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['ebola']</td>\n",
       "      <td>https://twitter.com/MSGUBOT/status/50626175419...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>506239829819281408</td>\n",
       "      <td>506239829819281408</td>\n",
       "      <td>2014-09-01 02:39:15 CEST</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>02:39:15</td>\n",
       "      <td>7.134575e+08</td>\n",
       "      <td>patriotsorg</td>\n",
       "      <td>Patriots Billboard</td>\n",
       "      <td>#SEIZED ISIS LAPTOP REVEALS THEY’RE DEVELOPING...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['seized']</td>\n",
       "      <td>https://twitter.com/PatriotsOrg/status/5062398...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id     conversation_id                created_at  \\\n",
       "0  506278868614148097  506278868614148097  2014-09-01 05:14:23 CEST   \n",
       "1  506272708037214208  506272708037214208  2014-09-01 04:49:54 CEST   \n",
       "2  506263382459428864  506263382459428864  2014-09-01 04:12:50 CEST   \n",
       "3  506261754197061632  506261754197061632  2014-09-01 04:06:22 CEST   \n",
       "4  506239829819281408  506239829819281408  2014-09-01 02:39:15 CEST   \n",
       "\n",
       "         date      time       user_id     username                  name  \\\n",
       "0  2014-09-01  05:14:23  8.343178e+07  starman1981    truckerstrong news   \n",
       "1  2014-09-01  04:49:54  7.134575e+08  patriotsorg    Patriots Billboard   \n",
       "2  2014-09-01  04:12:50  2.630728e+08       mlgeek        My Little Geek   \n",
       "3  2014-09-01  04:06:22  2.510451e+09      msgubot  Cédric Moro (backup)   \n",
       "4  2014-09-01  02:39:15  7.134575e+08  patriotsorg    Patriots Billboard   \n",
       "\n",
       "                                               tweet language  ... photos  \\\n",
       "0  ISIS laptop reveals terror group were working ...       en  ...     []   \n",
       "1  #SEIZED ISIS LAPTOP REVEALS THEY’RE DEVELOPING...       en  ...     []   \n",
       "2  @bjorntipling Perhaps Swift is a biological we...       en  ...     []   \n",
       "3  G+ #ebola USA created Ebola virus as biologica...       en  ...     []   \n",
       "4  #SEIZED ISIS LAPTOP REVEALS THEY’RE DEVELOPING...       en  ...     []   \n",
       "\n",
       "  replies_count retweets_count likes_count    hashtags  \\\n",
       "0             0            0.0         0.0          []   \n",
       "1             0            3.0         1.0  ['seized']   \n",
       "2             0            0.0         0.0          []   \n",
       "3             0            0.0         0.0   ['ebola']   \n",
       "4             1            2.0         1.0  ['seized']   \n",
       "\n",
       "                                                link retweet  video thumbnail  \\\n",
       "0  https://twitter.com/starman1981/status/5062788...   False  False       NaN   \n",
       "1  https://twitter.com/PatriotsOrg/status/5062727...   False  False       NaN   \n",
       "2  https://twitter.com/mlgeek/status/506263382459...   False  False       NaN   \n",
       "3  https://twitter.com/MSGUBOT/status/50626175419...   False  False       NaN   \n",
       "4  https://twitter.com/PatriotsOrg/status/5062398...   False  False       NaN   \n",
       "\n",
       "  reply_to  \n",
       "0       []  \n",
       "1       []  \n",
       "2       []  \n",
       "3       []  \n",
       "4       []  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(archive_pathnames[0])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a lot of information there. But what we are interested in is the user interactions around a topic that they might the government to track, for example. Therefore, we can count the number of tweets themselves, not any of their content or information, but also the number of likes and rerplies ! Each of these actions can make the user fear such surveillance. Retweets also, but because we also collect the retweets themselves, they are already there ! Therefore, we will first count the number of tweets per month, with the number of likes and retweets added as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replies_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>user_interactions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-31</th>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>207</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-29</th>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>177</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-31</th>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>192</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-30</th>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>156</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-31</th>\n",
       "      <td>46</td>\n",
       "      <td>17</td>\n",
       "      <td>237</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            replies_count  likes_count  tweet_count  user_interactions\n",
       "date                                                                  \n",
       "2012-01-31             49           51          207                307\n",
       "2012-02-29             33           27          177                237\n",
       "2012-03-31             37           10          192                239\n",
       "2012-04-30             40           32          156                228\n",
       "2012-05-31             46           17          237                300"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only interesting columns and sum them all together by month. We set to parse dates so we can group by month\n",
    "df = pd.read_csv(archive_pathnames[0], usecols=[\"date\", \"likes_count\", \"replies_count\"], parse_dates=[\"date\"], lineterminator='\\n')\n",
    "df[\"tweet_count\"] = 1\n",
    "grouped_df = df.set_index('date').groupby(pd.Grouper(freq='M')).sum()\n",
    "grouped_df[\"user_interactions\"] = grouped_df[\"likes_count\"] +  grouped_df[\"tweet_count\"] +  grouped_df[\"replies_count\"]\n",
    "\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to merge all twitter keyworkds into the same dataframe, therefore we will give the name of the keywork to the column where all values are summed, instead of just user_interactions. Let's extract the name from the archive path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>replies_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>tweet_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-31</th>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>207</td>\n",
       "      <td>131.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-29</th>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>177</td>\n",
       "      <td>145.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-31</th>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>192</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-30</th>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>156</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-31</th>\n",
       "      <td>46</td>\n",
       "      <td>17</td>\n",
       "      <td>237</td>\n",
       "      <td>36.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>237</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-31</th>\n",
       "      <td>57</td>\n",
       "      <td>89</td>\n",
       "      <td>227</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-31</th>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>263</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>192</td>\n",
       "      <td>32.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-31</th>\n",
       "      <td>36</td>\n",
       "      <td>146</td>\n",
       "      <td>215</td>\n",
       "      <td>179.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-30</th>\n",
       "      <td>50</td>\n",
       "      <td>101</td>\n",
       "      <td>237</td>\n",
       "      <td>125.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31</th>\n",
       "      <td>74</td>\n",
       "      <td>269</td>\n",
       "      <td>226</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-31</th>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>221</td>\n",
       "      <td>60.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-28</th>\n",
       "      <td>60</td>\n",
       "      <td>239</td>\n",
       "      <td>171</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-31</th>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>201</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-30</th>\n",
       "      <td>126</td>\n",
       "      <td>313</td>\n",
       "      <td>1463</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-31</th>\n",
       "      <td>70</td>\n",
       "      <td>125</td>\n",
       "      <td>379</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>45</td>\n",
       "      <td>69</td>\n",
       "      <td>266</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-31</th>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "      <td>258</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-31</th>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>263</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-30</th>\n",
       "      <td>75</td>\n",
       "      <td>58</td>\n",
       "      <td>242</td>\n",
       "      <td>81.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-31</th>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "      <td>232</td>\n",
       "      <td>115.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-30</th>\n",
       "      <td>37</td>\n",
       "      <td>74</td>\n",
       "      <td>154</td>\n",
       "      <td>307.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>2847.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>61</td>\n",
       "      <td>101</td>\n",
       "      <td>187</td>\n",
       "      <td>139.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>1170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-31</th>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "      <td>220</td>\n",
       "      <td>159.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>2177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-28</th>\n",
       "      <td>47</td>\n",
       "      <td>96</td>\n",
       "      <td>399</td>\n",
       "      <td>24.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-31</th>\n",
       "      <td>63</td>\n",
       "      <td>95</td>\n",
       "      <td>180</td>\n",
       "      <td>21.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-30</th>\n",
       "      <td>48</td>\n",
       "      <td>517</td>\n",
       "      <td>161</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-31</th>\n",
       "      <td>32</td>\n",
       "      <td>61</td>\n",
       "      <td>202</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-30</th>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>191</td>\n",
       "      <td>24.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-31</th>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>243</td>\n",
       "      <td>60.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-31</th>\n",
       "      <td>137</td>\n",
       "      <td>156</td>\n",
       "      <td>1075</td>\n",
       "      <td>24.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-30</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       1                                     2              \\\n",
       "           replies_count likes_count tweet_count replies_count likes_count   \n",
       "date                                                                         \n",
       "2012-01-31            49          51         207         131.0        65.0   \n",
       "2012-02-29            33          27         177         145.0       130.0   \n",
       "2012-03-31            37          10         192          22.0        14.0   \n",
       "2012-04-30            40          32         156          18.0        24.0   \n",
       "2012-05-31            46          17         237          36.0        26.0   \n",
       "2012-06-30            50          39         237          22.0        10.0   \n",
       "2012-07-31            57          89         227          15.0        20.0   \n",
       "2012-08-31            45          35         263          29.0        18.0   \n",
       "2012-09-30            39          14         192          32.0        78.0   \n",
       "2012-10-31            36         146         215         179.0       106.0   \n",
       "2012-11-30            50         101         237         125.0       114.0   \n",
       "2012-12-31            74         269         226          20.0        17.0   \n",
       "2013-01-31            55          50         221          60.0        44.0   \n",
       "2013-02-28            60         239         171          65.0        64.0   \n",
       "2013-03-31            40         100         201          15.0        17.0   \n",
       "2013-04-30           126         313        1463          19.0        18.0   \n",
       "2013-05-31            70         125         379          23.0        35.0   \n",
       "2013-06-30            45          69         266          36.0        33.0   \n",
       "2013-07-31            41          66         258           7.0         6.0   \n",
       "2013-08-31            61          52         263          42.0        44.0   \n",
       "2013-09-30            75          58         242          81.0        92.0   \n",
       "2013-10-31            31          46         232         115.0       147.0   \n",
       "2013-11-30            37          74         154         307.0       605.0   \n",
       "2013-12-31            61         101         187         139.0       242.0   \n",
       "2014-01-31            40          77         220         159.0       338.0   \n",
       "2014-02-28            47          96         399          24.0        40.0   \n",
       "2014-03-31            63          95         180          21.0        57.0   \n",
       "2014-04-30            48         517         161           5.0         6.0   \n",
       "2014-05-31            32          61         202          20.0        33.0   \n",
       "2014-06-30            54          53         191          24.0        52.0   \n",
       "2014-07-31            31          60         243          60.0       202.0   \n",
       "2014-08-31           137         156        1075          24.0       113.0   \n",
       "2014-09-30             2           3           7           NaN         NaN   \n",
       "\n",
       "                        \n",
       "           tweet_count  \n",
       "date                    \n",
       "2012-01-31      1419.0  \n",
       "2012-02-29      1838.0  \n",
       "2012-03-31       835.0  \n",
       "2012-04-30       409.0  \n",
       "2012-05-31      1223.0  \n",
       "2012-06-30       593.0  \n",
       "2012-07-31       320.0  \n",
       "2012-08-31       395.0  \n",
       "2012-09-30       689.0  \n",
       "2012-10-31      1122.0  \n",
       "2012-11-30      1748.0  \n",
       "2012-12-31       729.0  \n",
       "2013-01-31       775.0  \n",
       "2013-02-28       692.0  \n",
       "2013-03-31       100.0  \n",
       "2013-04-30       764.0  \n",
       "2013-05-31       228.0  \n",
       "2013-06-30       283.0  \n",
       "2013-07-31        47.0  \n",
       "2013-08-31       346.0  \n",
       "2013-09-30       332.0  \n",
       "2013-10-31      1011.0  \n",
       "2013-11-30      2847.0  \n",
       "2013-12-31      1170.0  \n",
       "2014-01-31      2177.0  \n",
       "2014-02-28       333.0  \n",
       "2014-03-31       284.0  \n",
       "2014-04-30        58.0  \n",
       "2014-05-31       301.0  \n",
       "2014-06-30       394.0  \n",
       "2014-07-31       738.0  \n",
       "2014-08-31       393.0  \n",
       "2014-09-30         NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(archive_pathnames[0], usecols=[\"date\", \"likes_count\", \"replies_count\"], parse_dates=[\"date\"], lineterminator='\\n')\n",
    "df[\"tweet_count\"] = 1\n",
    "grouped_df = df.set_index('date').groupby(pd.Grouper(freq='M')).sum()\n",
    "\n",
    "df1 = pd.read_csv(archive_pathnames[3], usecols=[\"date\", \"likes_count\", \"replies_count\"], parse_dates=[\"date\"], lineterminator='\\n')\n",
    "df1[\"tweet_count\"] = 1\n",
    "grouped_df1 = df1.set_index('date').groupby(pd.Grouper(freq='M')).sum()\n",
    "\n",
    "monthly_counts = pd.concat([grouped_df, grouped_df1], axis=1, keys=['1','2'])\n",
    "monthly_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/biological weapon_full.gz file\n",
      "Shape is : (9281, 2) \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ef42447ce93f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtotal_tweet_nb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_tweet_nb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape is : {df.shape} \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"We have {np.round(total_tweet_nb/1000000, 2)} million tweets as of the latest file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"We have {np.round(total_tweet_nb/1000000, 2)} million tweets !\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# print(pd.read_csv(archive_pathnames[0], usecols=[\"date\", \"likes_count\"]))\n",
    "total_tweet_nb = 0\n",
    "monthly_counts = pd.DataFrame([])\n",
    "\n",
    "for archive_pathname in archive_pathnames:\n",
    "    print(f\"Reading {archive_pathname} file\")\n",
    "    df = pd.read_csv(archive_pathname, usecols=[\"date\", \"likes_count\"], parse_dates=[\"date\"], lineterminator='\\n')\n",
    "    total_tweet_nb = total_tweet_nb + df.size\n",
    "    print(f\"Shape is : {df.shape} \\n\")\n",
    "    print(f\"We have {np.round(total_tweet_nb/1000000, 2)} million tweets as of the latest file\")\n",
    "    \n",
    "    df[\"tweet_count\"] = 1\n",
    "    df = df.set_index('date').groupby(pd.Grouper(freq='M')).sum()\n",
    "    monthly_counts = pd.merge(monthly_counts df)\n",
    "    \n",
    "print(f\"We have {np.round(total_tweet_nb/1000000, 2)} million tweets !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Couldn't find Spark, make sure SPARK_HOME env is set or Spark is in an expected location (e.g. from homebrew installation).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4f506673d71c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfindspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/findspark.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspark_home\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mspark_home\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpython_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/findspark.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspark_home\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         raise ValueError(\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;34m\"Couldn't find Spark, make sure SPARK_HOME env is set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;34m\" or Spark is in an expected location (e.g. from homebrew installation).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Couldn't find Spark, make sure SPARK_HOME env is set or Spark is in an expected location (e.g. from homebrew installation)."
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import random\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "num_samples = 100000000\n",
    "\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "\n",
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
